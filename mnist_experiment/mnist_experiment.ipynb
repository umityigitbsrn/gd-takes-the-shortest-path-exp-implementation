{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lenet import LeNet\n",
    "from utils import normalized_misfit, normalized_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# transformation on the data\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "target_transformation = transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# download dataset\n",
    "mnist_dataset = MNIST(root='./data', train=True, transform=transformation, target_transform=target_transformation, download=True)\n",
    "gen_idx_arr = range(len(mnist_dataset))\n",
    "\n",
    "# set the common parameters\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "num_classes = 10\n",
    "num_of_iterations = 1000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_of_training_round = 20\n",
    "\n",
    "## criterion\n",
    "criterion = torch.nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_tensor_500 = torch.zeros((num_of_iterations, len(list(LeNet(num_classes).parameters())) + 1, num_of_training_round))\n",
    "for training_round in range(num_of_training_round):\n",
    "    # dataset with 500 samples\n",
    "    dataset_500_indices = np.random.choice(gen_idx_arr, 500, replace=False)\n",
    "    mnist_dataset_500 = Subset(mnist_dataset, dataset_500_indices)\n",
    "\n",
    "    mnist_dataloader_500 = DataLoader(mnist_dataset_500, batch_size=batch_size, shuffle=True)\n",
    "    mnist_dataloader_500_mean_std = DataLoader(mnist_dataset_500, batch_size=len(mnist_dataset_500))\n",
    "    # find the normalization parameters (mean and std) for a channel\n",
    "    mean = None\n",
    "    std = None\n",
    "    for (data, _) in mnist_dataloader_500_mean_std:\n",
    "        data, _ = data.to(device), _.to(device)\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "\n",
    "    # model\n",
    "    model = LeNet(num_classes).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # save init model and weight parameters\n",
    "    init_model = copy.deepcopy(model).to(device)\n",
    "\n",
    "    # training\n",
    "    num_of_epoch = int(num_of_iterations / (len(mnist_dataset_500) / batch_size))\n",
    "\n",
    "    misfit_distance_dict = []\n",
    "    idx = 0\n",
    "    loss = None\n",
    "    for epoch in range(num_of_epoch):\n",
    "        for (data, label) in mnist_dataloader_500:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            data = (data - mean) / std\n",
    "\n",
    "            misfit_distance_dict.append({})\n",
    "\n",
    "            misfit_distance_dict[idx]['misfit'] = normalized_misfit(label, data, init_model, model)\n",
    "            result_tensor_500[idx, 0, training_round] = misfit_distance_dict[idx]['misfit']\n",
    "\n",
    "            misfit_distance_dict[idx]['distance'] = normalized_distance(init_model, model)\n",
    "            for val_idx, value in enumerate(misfit_distance_dict[idx]['distance'].values()):\n",
    "                result_tensor_500[idx, val_idx + 1, training_round] = value\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx = idx + 1\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print('training round: {}, epoch: {}/{}, loss: {}'.format(training_round + 1, epoch + 1, num_of_epoch, loss))\n",
    "\n",
    "    with open('./mnist_500_json/misfit_distance_{}.json'.format(training_round + 1), 'w') as fp:\n",
    "        json.dump(misfit_distance_dict, fp, indent=6)\n",
    "\n",
    "    print('training round: {} is done'.format(training_round + 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculating the average results\n",
    "mean_result_tensor_500 = result_tensor_500.mean(dim=2)\n",
    "\n",
    "legend_name_arr = list(filter(lambda x: x.find('weight') != -1, [name for name, _ in LeNet(10).named_parameters()]))\n",
    "\n",
    "# create the mean dict\n",
    "mean_misfit_distance_dict_500 = []\n",
    "for idx, row in enumerate(mean_result_tensor_500):\n",
    "    mean_misfit_distance_dict_500.append({})\n",
    "    mean_misfit_distance_dict_500[idx]['misfit'] = row[0].item()\n",
    "    for name_idx, name in enumerate(legend_name_arr):\n",
    "        mean_misfit_distance_dict_500[idx][name] = row[name_idx + 1].item()\n",
    "\n",
    "with open('./mnist_500_json/mean_misfit_distance_500.json', 'w') as fp:\n",
    "        json.dump(mean_misfit_distance_dict_500, fp, indent=6)\n",
    "\n",
    "plt.figure()\n",
    "for idx, name in enumerate(legend_name_arr):\n",
    "    plt.plot(mean_result_tensor_500[:, idx + 1], mean_result_tensor_500[:, 0], label=name)\n",
    "plt.xlabel('normalized distance')\n",
    "plt.ylabel('normalized misfit')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_tensor_5000 = torch.zeros((num_of_iterations, len(list(LeNet(num_classes).parameters())) + 1, num_of_training_round))\n",
    "for training_round in range(num_of_training_round):\n",
    "    # dataset with 5000 samples\n",
    "    dataset_5000_indices = np.random.choice(gen_idx_arr, 5000, replace=False)\n",
    "    mnist_dataset_5000 = Subset(mnist_dataset, dataset_5000_indices)\n",
    "\n",
    "    mnist_dataloader_5000 = DataLoader(mnist_dataset_5000, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # model\n",
    "    model = LeNet(num_classes).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # save init model and weight parameters\n",
    "    init_model = copy.deepcopy(model).to(device)\n",
    "\n",
    "    # training\n",
    "    num_of_epoch = int(num_of_iterations / (len(mnist_dataset_5000) / batch_size))\n",
    "\n",
    "    misfit_distance_dict = []\n",
    "    idx = 0\n",
    "    loss = None\n",
    "    for epoch in range(num_of_epoch):\n",
    "        for (data, label) in mnist_dataloader_5000:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "\n",
    "            misfit_distance_dict.append({})\n",
    "\n",
    "            misfit_distance_dict[idx]['misfit'] = normalized_misfit(label, data, init_model, model)\n",
    "            result_tensor_5000[idx, 0, training_round] = misfit_distance_dict[idx]['misfit']\n",
    "\n",
    "            misfit_distance_dict[idx]['distance'] = normalized_distance(init_model, model)\n",
    "            for val_idx, value in enumerate(misfit_distance_dict[idx]['distance'].values()):\n",
    "                result_tensor_5000[idx, val_idx + 1, training_round] = value\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx = idx + 1\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print('training round: {}, epoch: {}/{}, loss: {}'.format(training_round + 1, epoch + 1, num_of_epoch, loss))\n",
    "\n",
    "    with open('./mnist_5000_json/misfit_distance_{}.json'.format(training_round + 1), 'w') as fp:\n",
    "        json.dump(misfit_distance_dict, fp, indent=6)\n",
    "\n",
    "    print('training round: {} is done'.format(training_round + 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculating the average results\n",
    "mean_result_tensor_5000 = result_tensor_5000.mean(dim=2)\n",
    "\n",
    "legend_name_arr = list(filter(lambda x: x.find('weight') != -1, [name for name, _ in LeNet(10).named_parameters()]))\n",
    "\n",
    "# create the mean dict\n",
    "mean_misfit_distance_dict_5000 = []\n",
    "for idx, row in enumerate(mean_result_tensor_5000):\n",
    "    mean_misfit_distance_dict_5000.append({})\n",
    "    mean_misfit_distance_dict_5000[idx]['misfit'] = row[0].item()\n",
    "    for name_idx, name in enumerate(legend_name_arr):\n",
    "        mean_misfit_distance_dict_5000[idx][name] = row[name_idx + 1].item()\n",
    "\n",
    "with open('./mnist_5000_json/mean_misfit_distance_5000.json', 'w') as fp:\n",
    "        json.dump(mean_misfit_distance_dict_5000, fp, indent=6)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for idx, name in enumerate(legend_name_arr):\n",
    "    plt.plot(mean_result_tensor_5000[:, idx + 1], mean_result_tensor_5000[:, 0], label=name)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
